{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import displayData as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "import checkNNGradients as check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD4CAYAAADl7fPiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQ+klEQVR4nO3dfaxU9Z3H8c/njlxRRLQ+gCJLiSIJaRRd4raSGNxuDRBT2tV1IZst6ZJgG022yTZZdzdp638mG9qkYrR0S9TEqm12acmWKMSsQZOyFQg+sIJcEZcrCFsfUKI83Hu/+8eca+7vMgO/ebozd3y/EjIz53znzO/kcj+cM+fH+ToiBADDeto9AACdhVAAkCAUACQIBQAJQgFA4px2D6AS29HTQ14BrTI0NKSIcKV1HRkKPT09mjhxYruHAXSt48ePV13HP8cAEg2Fgu1FtvfY7rN9X4X1tv3TYv0rtm9s5PMAtF7doWC7JOkhSYslzZW03PbcUWWLJc0u/qyS9HC9nwdgbDRypHCTpL6I2BcRJyU9JWnpqJqlkh6Psq2SLrJ9RQOfCaDFGgmF6ZIOjHjdXyyrtUaSZHuV7W22t/H/MYD2aeTqQ6XLGaN/m3Nqygsj1kpaK0mlUolUANqkkSOFfkkzRry+StLBOmoAdJBGQuElSbNtz7LdK2mZpA2jajZI+lZxFeLLko5GxKEGPhNAi9V9+hARA7bvlfSspJKkdRGxy/Z3ivWPSNooaYmkPkmfSPp240MG0EruxC/1SqVSMKMRaJ3jx49rcHCw4jRnZjQCSBAKABKEAoAEoQAgQSgASBAKABKEAoAEoQAgQSgASBAKABIdeeNWoNUGBwez6k6dOpW9zW6Zms+RAoAEoQAgQSgASBAKABKEAoAEoQAgQSgASDTSIWqG7f+y/brtXbb/vkLNQttHbe8s/vygseECaLVGJi8NSPqHiNhhe7Kk7bY3R8T/jKp7ISJub+BzAIyhuo8UIuJQROwonn8s6XVV6f4EYPxoyjRn21+UdIOk/66w+iu2X1a5Ccz3I2JXlW2sUrkJreyKN5kdUwMDA9m1pVIpq64T9qubDQ0NZddOn57379cNN9yQvc3Nmzdn19YyfXqs/940HAq2L5D075K+FxEfjVq9Q9LMiDhme4mk36jcgfo0tI0DOkNDVx9sT1A5EJ6IiP8YvT4iPoqIY8XzjZIm2L60kc8E0FqNXH2wpF9Iej0iflylZlpRJ9s3FZ/3Xr2fCaD1Gjl9WCDpbyW9antnseyfJf2J9FnbuDslfdf2gKRPJS2LTmxJBeAzjfSSfFGVW82PrFkjaU29nwFg7DGjEUCCUACQIBQAJAgFAAlCAUBi3N/NuZYrnL29vdm18+fPz6598803s+reey9/ikZPD3ldq9w7NEvSggULsuqWLFmSvc0tW7Zk1548eTK7dqynOfM3D0CCUACQIBQAJAgFAAlCAUCCUACQIBQAJAgFAAlCAUBi3M9orOVmnVOmTMmuveeee7JrV69enVV3+PDh7G3WMvsSZbX8Xci9Ievx48ezt9nJsxRrwZECgAShACDR6N2c99t+tWgJt63Cetv+qe0+26/YvrGRzwPQes34TuHWiPhjlXWLVe7zMFvSn0l6uHgE0KFaffqwVNLjUbZV0kW2r2jxZwJoQKOhEJI22d5etH0bbbqkAyNe96tKv0nbq2xvs72Nu8AD7dPo6cOCiDho+3JJm23vjoiRd5qodN2l4m88beOAztDQkUJEHCwej0haL+mmUSX9kmaMeH2Vyo1mAXSoRtrGTbI9efi5pNskvTaqbIOkbxVXIb4s6WhEHKp7tABarpHTh6mS1hczs86R9MuIeMb2d6TP2sZtlLREUp+kTyR9u7HhAmi1RtrG7ZN0fYXlj4x4HpLy5wvXN47s2gsuuCC7du7cudm1AwMD2bWoTS1Th3OnLkvSHXfckVX34IMPZm/z2LFj2bXnnntudu1YY0YjgAShACBBKABIEAoAEoQCgAShACBBKABIEAoAEoQCgAShACAx7u/mXMs052uvvTa7dtKkSfUMB01WyxTyOXPmZNdedtllWXVbt27N3mapVMqu7WQcKQBIEAoAEoQCgAShACBBKABIEAoAEoQCgEQjN26dU7SLG/7zke3vjapZaPvoiJofNDxiAC3VyD0a90iaJ0m2S5LeUfk276O9EBG31/s5AMZWs04fvirpzYh4u0nbA9AmzZrmvEzSk1XWfcX2yyo3gfl+ROyqVFS0nVtVPG/SsFILFy7Mrh0aGsquzb3jcKv2qxad0JKvlqnLtdz1uJafb+4YDh7M713U09MdX9E1vBe2eyV9XdKvK6zeIWlmRFwv6UFJv6m2nYhYGxHzI2J+J/zyAJ9XzYi2xZJ2RMTh0Ssi4qOIOFY83yhpgu1Lm/CZAFqkGaGwXFVOHWxPc/HPvu2bis97rwmfCaBFGvpOwfb5kr4m6e4Ry0a2jbtT0ndtD0j6VNKy6ISTWgBVNRQKEfGJpEtGLRvZNm6NpDWNfAaAsdUdX5cCaBpCAUCCUACQIBQAJAgFAIlxfzfnWlxyySVnLyq89dZb2bX9/f1ZdadOncreZi1XbmuZAdrb25tdW8u03fPPPz+79pprrsmuveuuu7JrV6xYkV37xBNPZNUdOXIke5vdMhOXIwUACUIBQIJQAJAgFAAkCAUACUIBQIJQAJAgFAAkCAUACUIBQOJzNc25FtOmTcuuveWWW7LqPvzww+xtzpgxI7t21qxZ2bXXXXdddm0tU6JnzpyZXXv48Gm386zqwIED2bUTJkzIrn3++eez6j799NPsbdZy5+lOxpECgMRZQ8H2OttHbL82YtkXbG+2vbd4vLjKexfZ3mO7z/Z9zRw4gNbIOVJ4VNKiUcvuk/RcRMyW9FzxOlG0kntI5VvAz5W03PbchkYLoOXOGgoRsUXS+6MWL5X0WPH8MUnfqPDWmyT1RcS+iDgp6anifQA6WL3fKUyNiEOSVDxeXqFmuqSR3xL1F8sAdLBWXn2odMeJqncOGYtekgDOrt4jhcO2r5Ck4rHS7Wn6JY28rnaVyk1mK6KXJNAZ6g2FDZKG7321QtJvK9S8JGm27VlFE9plxfsAdLCcS5JPSvq9pDm2+22vlPSApK/Z3qty27gHitorbW+UpIgYkHSvpGclvS7pV9Xa0APoHGf9TiEilldZ9dUKtQclLRnxeqOkjXWPDsCYG/fTnGv5/uHpp5/Orr366quza++///6sulru5jx58uTs2v3792fX7tixI7u2r68vu3bv3r3Ztbt3786uvfnmm7NrV65cmV377rvvZtUNDQ1lb7NbMM0ZQIJQAJAgFAAkCAUACUIBQIJQAJAgFAAkCAUACUIBQIJQAJAY99Oczzknfxc2bdqUXbt9+/bs2nbfxffo0aPZtR9//HF27cDAQHZtLT+HWqYO33nnndm1e/bsya59++23s+pq2a9uwZECgAShACBBKABIEAoAEoQCgAShACBBKABI1NtL8l9t77b9iu31ti+q8t79tl+1vdP2tiaOG0CL1NtLcrOkL0XEdZLekPRPZ3j/rRExLyLm1zdEAGOprl6SEbGpuIW7JG1VudELgC7QjDmcfyep2m2SQ9Im2yHpZxGxttpGxqJtXC1TVt9/f3RP3eoiqnbDS9SyX7nblKSenvyvhiZMmJBd29vbm11bi1ruaj1x4sTs2jfeeCO79uDBqs3KEqVSKXub3aKhULD9L5IGJD1RpWRBRBy0fbmkzbZ3F0cepykCY60klUql/N8IAE1V99UH2ysk3S7pb6LKP2tFcxhFxBFJ61VuTw+gg9UVCrYXSfpHSV+PiE+q1EyyPXn4uaTbJL1WqRZA56i3l+QaSZNVPiXYafuRovazXpKSpkp60fbLkv4g6XcR8UxL9gJA09TbS/IXVWo/6yUZEfskXd/Q6ACMOWY0AkgQCgAShAKABKEAIEEoAEh8/m5Vm+nzOL21E9Vy5+cLL7wwu/a8887Lqjtx4kT2NrsFRwoAEoQCgAShACBBKABIEAoAEoQCgAShACBBKABIEAoAEsxoREerZUbj5MmTs2tzZzR+8MEH2dvsFhwpAEgQCgAS9baN+5Htd4r7M+60vaTKexfZ3mO7z/Z9zRw4gNaot22cJP2kaAc3LyI2jl5puyTpIUmLJc2VtNz23EYGC6D16mobl+kmSX0RsS8iTkp6StLSOrYDYAw18p3CvUXX6XW2L66wfrqkAyNe9xfLKrK9yvY229tqaZkGoLnqDYWHJV0taZ6kQ5JWV6ip1Dix6m97RKyNiPkRMb9VvSQBnF1doRARhyNiMCKGJP1cldvB9UuaMeL1VZLyunoCaJt628ZdMeLlN1W5HdxLkmbbnmW7V9IySRvq+TwAY+esMxqLtnELJV1qu1/SDyUttD1P5dOB/ZLuLmqvlPRvEbEkIgZs3yvpWUklSesiYlcrdgJA87SsbVzxeqOk0y5XArl6evIPZqdOnZpdO2XKlKy6/v7+7G12C2Y0AkgQCgAShAKABKEAIEEoAEgQCgAShAKABKEAIEEoAEgQCgAS3M0ZY66W/xr/wgsvZNdOmzYtu/bEiRNZdZ/H/8bPkQKABKEAIEEoAEgQCgAShAKABKEAIEEoAEjk3KNxnaTbJR2JiC8Vy56WNKcouUjShxExr8J790v6WNKgpIGImN+UUQNomZzJS49KWiPp8eEFEfHXw89tr5Z09AzvvzUi/ljvAAGMrZwbt26x/cVK61ye7nWXpD9v8rgAtIlzWrQVofCfw6cPI5bfIunH1U4LbL8l6QOVbwX/s4hYe4bPWCVpVfH8T88777zcfUAXGxwczK6tpd1gqVTKquvWac7Hjx/X4OBgxZ1r9P8+LJf05BnWL4iIg7Yvl7TZ9u6iYe1pisBYK0mlUolmkkCb1H31wfY5kv5S0tPVaoo+EIqII5LWq3J7OQAdpJFLkn8haXdEVOyWYXuS7cnDzyXdpsrt5QB0kLOGQtE27veS5tjut72yWLVMo04dbF9pe7gj1FRJL9p+WdIfJP0uIp5p3tABtELWF41jrVQqxcSJE9s9DHQAvmhsjTN90ciMRgAJQgFAglAAkCAUACQIBQAJ7uaMjpZ7lQDNw5ECgAShACBBKABIEAoAEoQCgAShACBBKABIEAoAEoQCgAShACDRkTdZsf1/kt4etfhSSd3YP6Jb90vq3n3rhv2aGRGXVVrRkaFQie1t3dhhqlv3S+refevW/RrG6QOABKEAIDGeQqFqd6lxrlv3S+refevW/ZI0jr5TADA2xtORAoAxQCgASHR8KNheZHuP7T7b97V7PM1ke7/tV23vtL2t3eOpl+11to/Yfm3Esi/Y3mx7b/F4cTvHWK8q+/Yj2+8UP7edtpe0c4zN1tGhYLsk6SFJiyXNlbTc9tz2jqrpbo2IeeP8uvejkhaNWnafpOciYrak54rX49GjOn3fJOknxc9tXkRsrLB+3OroUFC5S3VfROyLiJOSnpK0tM1jwigRsUXS+6MWL5X0WPH8MUnfGMsxNUuVfetqnR4K0yUdGPG6v1jWLULSJtvbba9q92CabGpEHJKk4vHyNo+n2e61/UpxejEuT42q6fRQqNQAs5uuoS6IiBtVPj26x/Yt7R4Qsjws6WpJ8yQdkrS6raNpsk4PhX5JM0a8vkrSwTaNpeki4mDxeETSepVPl7rFYdtXSFLxeKTN42maiDgcEYMRMSTp5+qun1vHh8JLkmbbnmW7V9IySRvaPKamsD3J9uTh55Juk/Tamd81rmyQtKJ4vkLSb9s4lqYaDrvCN9VdP7fO7hAVEQO275X0rKSSpHURsavNw2qWqZLW25bKP4dfRsQz7R1SfWw/KWmhpEtt90v6oaQHJP3K9kpJ/yvpr9o3wvpV2beFtuepfCq7X9Ld7RpfKzDNGUCi008fAIwxQgFAglAAkCAUACQIBQAJQgFAglAAkPh/kVa6c5O+3oEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = loadmat('ex4data1.mat')\n",
    "Y = data['y']\n",
    "X = data['X']\n",
    "\n",
    "nMuestras = len(X)\n",
    "Y = np.ravel(Y)\n",
    "\n",
    "\n",
    "print(Y[2000])\n",
    "plt.figure()\n",
    "dp.displayImage(X[2000])\n",
    "plt.savefig(\"Input_sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = loadmat('ex4weights.mat')\n",
    "theta1,theta2 = weights['Theta1'],weights['Theta2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIGMOIDE \n",
    "def sigmoide(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "def sigmoideDerivada(value):\n",
    "    temp = sigmoide(value)\n",
    "    return temp * (1 - temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retro-propagacion -> Forward propagation\n",
    "El algoritmo de retro-propagación nos permite calcular el gradiente de la función de coste de la red neuronal.\n",
    "\n",
    "Para ello se utilizaran 2 funciones, forwardProp y backprop.\n",
    "\n",
    "ForwardProp es una funcion de hipotesis que utiliza un valor de entrada para predecir una salida mediante una matriz de pesos. Tambien añadira un termino de sesgo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor predicho para el elemento 0 de X segun la hipotesis:  9\n"
     ]
    }
   ],
   "source": [
    "def forwardProp(Theta1, Theta2, X):\n",
    "    z1 = Theta1.dot(X.T)\n",
    "    a1 = sigmoide(z1)\n",
    "    tuple = (np.ones(len(a1[0])), a1)\n",
    "    a1 = np.vstack(tuple)\n",
    "    z2 = Theta2.dot(a1)\n",
    "    a2 = sigmoide(z2)\n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "X_aux = np.hstack([np.ones((len(X), 1)), X])\n",
    "print(\"Valor predicho para el elemento 0 de X segun la hipotesis: \", \n",
    "      (forwardProp(theta1, theta2, X_aux)[3]).T[0].argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de coste\n",
    "La función de coste, se implementara con regularización. Como entrada a dicha función, hemos de preparar un vector de Y distinto al recibido. Será una matriz de (numElementos, numEtiquetas) donde cada fila corresponde a un caso. Cada fila tendrá todos los valores a cero menos el valor real que representa ese caso, que estará a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFun(X, y, theta1, theta2, reg):\n",
    "    #Cambios para poder operar\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    muestras = len(y)\n",
    "\n",
    "    theta1 = np.array(theta1)\n",
    "    theta2 = np.array(theta2)\n",
    "    \n",
    "    #predecimos la salida de los valores para la matriz de pesos de theta y nos quedamos con el valor predicho en la\n",
    "    #variable hipothesis y calculamos el coste con el valor de dicha variable\n",
    "    hipothesis  = forwardProp(theta1, theta2, X)[3]\n",
    "    cost = np.sum((-y.T)*(np.log(hipothesis)) - (1-y.T)*(np.log(1- hipothesis)))/muestras\n",
    "    \n",
    "    #calculo del coste con regularización \n",
    "    regcost = np.sum(np.power(theta1[:, 1:], 2)) + np.sum(np.power(theta2[:,1:], 2))\n",
    "    regcost = regcost * (reg/(2*muestras))\n",
    "\n",
    "    return cost + regcost\n",
    "\n",
    "def getYMatrix(Y, nEtiquetas):\n",
    "    nY = np.zeros((len(Y), nEtiquetas))\n",
    "    yaux = np.array(Y) -1\n",
    "    \n",
    "    for i in range(len(nY)):\n",
    "        z = yaux[i]\n",
    "        if(isinstance(z, np.uint8)):\n",
    "            if(z == 10): z = 0\n",
    "            nY[i][z] = 1\n",
    "        else:\n",
    "            z = yaux[i].all()\n",
    "            if(z == 10): z = 0\n",
    "            nY[i][z] = 1\n",
    "            \n",
    "    return nY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El coste con thetas entrenados es:  0.3837698590909236\n"
     ]
    }
   ],
   "source": [
    "Y_aux = getYMatrix(Y, 10)\n",
    "\n",
    "print(\"El coste con thetas entrenados es: \", costFun(X_aux, Y_aux, theta1, theta2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BackPropagation\n",
    "\n",
    "Backpropagation se usa para repartir el error entre las neuronas de la red neuronal. \n",
    "Comienza desde la ultima capa y desde esa desciende hasta la penúltima, ya que no se puede \n",
    "repartir error para la capa de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Devuelve el coste y el gradiente de una red neuronal de 3 capas\n",
    "def backprop(params_rn, num_entradas,num_ocultas, num_etiquetas, X, Y, reg):\n",
    "    th1 = np.reshape(params_rn[:num_ocultas *(num_entradas + 1)],(num_ocultas, (num_entradas+1)))\n",
    "    # theta2 es un array de (num_etiquetas, num_ocultas)\n",
    "    th2 = np.reshape(params_rn[num_ocultas*(num_entradas + 1): ], (num_etiquetas,(num_ocultas+1)))\n",
    "    \n",
    "    X_unos = np.hstack([np.ones((len(X), 1)), X])\n",
    "    nMuestras = len(X)\n",
    "    y = np.zeros((nMuestras, num_etiquetas))\n",
    "    \n",
    "    y = y + getYMatrix(Y, num_etiquetas)\n",
    "    \n",
    "    coste = costFun(X_unos, y, th1, th2, reg)\n",
    "    \n",
    "    #Backpropagation\n",
    "    \n",
    "    # Forward propagation para obtener una hipótesis y los valores intermedios\n",
    "    # de la red neuronal\n",
    "    z2, a2, z3, a3 = forwardProp(th1, th2, X_unos)\n",
    "    \n",
    "    gradW1 = np.zeros(th1.shape)\n",
    "    gradW2 = np.zeros(th2.shape)\n",
    "    \n",
    "    # Coste por capas\n",
    "    delta3 = np.array(a3 - y.T)\n",
    "    delta2 = th2.T[1:, :].dot(delta3)*sigmoideDerivada(z2)\n",
    "    \n",
    "    # Acumulacion de gradiente\n",
    "    gradW1 = gradW1 + (delta2.dot(X_unos))\n",
    "    gradW2 = gradW2 + (delta3.dot(a2.T))\n",
    "    \n",
    "    G1 = gradW1/float(nMuestras)\n",
    "    G2 = gradW2/float(nMuestras)\n",
    "    \n",
    "    # suma definitiva\n",
    "    G1[:, 1: ] = G1[:, 1:] + (float(reg)/float(nMuestras))*th1[:, 1:]\n",
    "    G2[:, 1: ] = G2[:, 1:] + (float(reg)/float(nMuestras))*th2[:, 1:]\n",
    "    \n",
    "    gradients = np.concatenate((G1, G2), axis = None)\n",
    "    \n",
    "    return coste, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad shape:  (38,)\n",
      "num grad shape:  (38,)\n",
      "Diferencias al comprobar gradientes:\n",
      " [ 1.14376869e-10  9.90318938e-14  7.07486847e-12  3.08568171e-11\n",
      " -1.16232968e-10  2.46816456e-12 -3.54113683e-11 -1.05037617e-10\n",
      " -1.62812763e-10  9.56501545e-12 -7.94193045e-11 -2.43810860e-10\n",
      " -6.30041019e-11  3.38154504e-12 -2.59059441e-11 -7.55736862e-11\n",
      "  4.48127369e-11  9.81270620e-13  3.02057060e-11  5.07995868e-11\n",
      "  6.21964702e-11  1.66536784e-11  8.51685389e-12  4.28107549e-12\n",
      "  1.72283854e-11  1.71411774e-11  7.11513071e-11  1.42481582e-11\n",
      "  7.72014397e-12  1.38438705e-11  1.58183466e-11  2.05401252e-11\n",
      "  6.97608638e-11  1.60036984e-11  1.89406824e-12  1.83976445e-11\n",
      "  2.21591356e-11  2.11061169e-11]\n"
     ]
    }
   ],
   "source": [
    "params = np.concatenate((theta1, theta2), axis = None)\n",
    "print(\"Diferencias al comprobar gradientes:\\n\", check.checkNNGradients(backprop, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializacion aleatoria de thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitRandomWeight(L_in, L_out):\n",
    "    cini = 0.2\n",
    "    a = np.random.uniform(-cini, cini, size = (L_in, L_out))\n",
    "    a = np.insert(a, 0, 1, axis = 0)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de la red Neuronal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNTest (num_entradas, num_ocultas, num_etiquetas, reg, X, Y, laps):\n",
    "    t1 = InitRandomWeight(num_entradas, num_ocultas)\n",
    "    t2 = InitRandomWeight(num_ocultas, num_etiquetas)\n",
    "\n",
    "    params = np.hstack((np.ravel(t1), np.ravel(t2)))\n",
    "    out = opt.minimize(fun = backprop, x0 = params, args = (num_entradas, num_ocultas, num_etiquetas, X, Y, reg), method='TNC', jac = True, options = {'maxiter': laps})\n",
    "\n",
    "    Thetas1 = out.x[:(num_ocultas*(num_entradas+1))].reshape(num_ocultas,(num_entradas+1))\n",
    "    Thetas2 = out.x[(num_ocultas*(num_entradas+1)):].reshape(num_etiquetas,(num_ocultas+1))\n",
    "\n",
    "    input = np.hstack([np.ones((len(X), 1)), X])\n",
    "    hipo = forwardProp(Thetas1, Thetas2, input)[3]\n",
    "\n",
    "\n",
    "    Ghipo = (hipo.argmax(axis = 0))+1\n",
    "    prec = (Ghipo == Y)*1\n",
    "    \n",
    "    precision = sum(prec) / len(X)\n",
    "\n",
    "    print(\"Program precision: \", precision *100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program precision:  87.14 %\n"
     ]
    }
   ],
   "source": [
    "NNTest(400, 25, 10, 1, X, Y, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program precision:  97.64 %\n"
     ]
    }
   ],
   "source": [
    "NNTest(400, 25, 10, 1, X, Y, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program precision:  17.72 %\n"
     ]
    }
   ],
   "source": [
    "NNTest(400, 25, 10, 1, X, Y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
